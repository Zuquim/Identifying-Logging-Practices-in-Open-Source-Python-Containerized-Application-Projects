{"huawei-noah.Pretrained-Language-Model/BBPE/tokenizationBBPE.py": {"loc": 535, "lloc": 380, "sloc": 353, "comments": 68, "multi": 30, "blank": 78, "single_comments": 74}, "huawei-noah.Pretrained-Language-Model/BBPE/bbpe/map_freq.py": {"loc": 115, "lloc": 83, "sloc": 75, "comments": 32, "multi": 0, "blank": 9, "single_comments": 31}, "huawei-noah.Pretrained-Language-Model/BBPE/bbpe/mergeVocab.py": {"loc": 81, "lloc": 50, "sloc": 49, "comments": 20, "multi": 0, "blank": 13, "single_comments": 19}, "huawei-noah.Pretrained-Language-Model/BBPE/bbpe/utf-8-mt-byte.py": {"loc": 145, "lloc": 110, "sloc": 105, "comments": 31, "multi": 0, "blank": 20, "single_comments": 20}, "huawei-noah.Pretrained-Language-Model/BBPE/bbpe/utf-8-mt-char.py": {"loc": 127, "lloc": 91, "sloc": 89, "comments": 26, "multi": 0, "blank": 19, "single_comments": 19}, "huawei-noah.Pretrained-Language-Model/BBPE/bbpe/fastBPE-master/vocab_byteTo16base.py": {"loc": 106, "lloc": 75, "sloc": 72, "comments": 24, "multi": 0, "blank": 13, "single_comments": 21}, "huawei-noah.Pretrained-Language-Model/DynaBERT/eval_glue.py": {"loc": 359, "lloc": 232, "sloc": 263, "comments": 30, "multi": 0, "blank": 64, "single_comments": 32}, "huawei-noah.Pretrained-Language-Model/DynaBERT/run_glue.py": {"loc": 575, "lloc": 375, "sloc": 412, "comments": 59, "multi": 9, "blank": 99, "single_comments": 55}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/configuration_bert.py": {"loc": 115, "lloc": 35, "sloc": 63, "comments": 15, "multi": 26, "blank": 10, "single_comments": 16}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/configuration_roberta.py": {"loc": 35, "lloc": 9, "sloc": 12, "comments": 15, "multi": 0, "blank": 7, "single_comments": 16}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/configuration_utils.py": {"loc": 207, "lloc": 95, "sloc": 94, "comments": 21, "multi": 50, "blank": 38, "single_comments": 25}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/file_utils.py": {"loc": 324, "lloc": 223, "sloc": 216, "comments": 24, "multi": 34, "blank": 56, "single_comments": 18}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/modeling_bert.py": {"loc": 626, "lloc": 420, "sloc": 430, "comments": 64, "multi": 30, "blank": 105, "single_comments": 61}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/modeling_roberta.py": {"loc": 470, "lloc": 153, "sloc": 223, "comments": 25, "multi": 136, "blank": 89, "single_comments": 22}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/modeling_utils.py": {"loc": 798, "lloc": 419, "sloc": 414, "comments": 70, "multi": 195, "blank": 137, "single_comments": 52}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/optimization.py": {"loc": 189, "lloc": 102, "sloc": 94, "comments": 30, "multi": 33, "blank": 32, "single_comments": 30}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/tokenization_bert.py": {"loc": 502, "lloc": 260, "sloc": 299, "comments": 45, "multi": 86, "blank": 64, "single_comments": 53}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/tokenization_gpt2.py": {"loc": 234, "lloc": 152, "sloc": 158, "comments": 22, "multi": 25, "blank": 29, "single_comments": 22}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/tokenization_roberta.py": {"loc": 140, "lloc": 55, "sloc": 71, "comments": 18, "multi": 34, "blank": 18, "single_comments": 17}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/tokenization_utils.py": {"loc": 1068, "lloc": 550, "sloc": 559, "comments": 37, "multi": 269, "blank": 184, "single_comments": 56}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/__init__.py": {"loc": 168, "lloc": 27, "sloc": 40, "comments": 116, "multi": 0, "blank": 13, "single_comments": 115}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/__main__.py": {"loc": 129, "lloc": 94, "sloc": 115, "comments": 7, "multi": 0, "blank": 7, "single_comments": 7}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/data/__init__.py": {"loc": 6, "lloc": 5, "sloc": 5, "comments": 0, "multi": 0, "blank": 1, "single_comments": 0}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/data/metrics/__init__.py": {"loc": 83, "lloc": 57, "sloc": 56, "comments": 15, "multi": 0, "blank": 12, "single_comments": 15}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/data/processors/glue.py": {"loc": 929, "lloc": 516, "sloc": 579, "comments": 147, "multi": 20, "blank": 114, "single_comments": 216}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/data/processors/utils.py": {"loc": 125, "lloc": 64, "sloc": 51, "comments": 16, "multi": 26, "blank": 22, "single_comments": 26}, "huawei-noah.Pretrained-Language-Model/DynaBERT/transformers/data/processors/__init__.py": {"loc": 3, "lloc": 2, "sloc": 2, "comments": 0, "multi": 0, "blank": 1, "single_comments": 0}, "huawei-noah.Pretrained-Language-Model/NEZHA-Gen-TensorFlow/interactive_conditional_generation.py": {"loc": 1099, "lloc": 389, "sloc": 582, "comments": 107, "multi": 235, "blank": 169, "single_comments": 113}, "huawei-noah.Pretrained-Language-Model/NEZHA-Gen-TensorFlow/poetry.py": {"loc": 1282, "lloc": 512, "sloc": 688, "comments": 111, "multi": 268, "blank": 204, "single_comments": 122}, "huawei-noah.Pretrained-Language-Model/NEZHA-Gen-TensorFlow/tokenization.py": {"loc": 399, "lloc": 257, "sloc": 254, "comments": 49, "multi": 16, "blank": 68, "single_comments": 61}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/convert_tf_checkpoint_to_pytorch.py": {"loc": 125, "lloc": 77, "sloc": 93, "comments": 20, "multi": 0, "blank": 11, "single_comments": 21}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/file_utils.py": {"loc": 249, "lloc": 164, "sloc": 154, "comments": 14, "multi": 32, "blank": 48, "single_comments": 15}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/modeling_nezha.py": {"loc": 1115, "lloc": 666, "sloc": 708, "comments": 56, "multi": 180, "blank": 169, "single_comments": 58}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/optimization.py": {"loc": 179, "lloc": 95, "sloc": 99, "comments": 33, "multi": 22, "blank": 24, "single_comments": 34}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/run_sequence_classifier.py": {"loc": 1062, "lloc": 713, "sloc": 803, "comments": 69, "multi": 10, "blank": 140, "single_comments": 109}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/tools/file_utils.py": {"loc": 238, "lloc": 155, "sloc": 144, "comments": 14, "multi": 32, "blank": 47, "single_comments": 15}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/tools/official_tokenization.py": {"loc": 388, "lloc": 256, "sloc": 258, "comments": 47, "multi": 20, "blank": 51, "single_comments": 59}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/tools/pytorch_optimization.py": {"loc": 197, "lloc": 96, "sloc": 116, "comments": 30, "multi": 18, "blank": 32, "single_comments": 31}, "huawei-noah.Pretrained-Language-Model/NEZHA-PyTorch/tools/utils.py": {"loc": 153, "lloc": 113, "sloc": 113, "comments": 12, "multi": 0, "blank": 28, "single_comments": 12}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/extract_features.py": {"loc": 419, "lloc": 216, "sloc": 281, "comments": 49, "multi": 0, "blank": 81, "single_comments": 57}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/fp16_utils.py": {"loc": 35, "lloc": 9, "sloc": 14, "comments": 15, "multi": 3, "blank": 3, "single_comments": 15}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/fused_layer_norm.py": {"loc": 141, "lloc": 76, "sloc": 113, "comments": 24, "multi": 0, "blank": 4, "single_comments": 24}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/gpu_environment.py": {"loc": 36, "lloc": 11, "sloc": 16, "comments": 14, "multi": 3, "blank": 3, "single_comments": 14}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/modeling.py": {"loc": 1269, "lloc": 433, "sloc": 617, "comments": 135, "multi": 320, "blank": 186, "single_comments": 146}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/modeling_ori.py": {"loc": 998, "lloc": 346, "sloc": 484, "comments": 97, "multi": 243, "blank": 162, "single_comments": 109}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/modeling_test.py": {"loc": 277, "lloc": 167, "sloc": 219, "comments": 14, "multi": 0, "blank": 40, "single_comments": 18}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/optimization.py": {"loc": 309, "lloc": 153, "sloc": 220, "comments": 40, "multi": 0, "blank": 38, "single_comments": 51}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/optimization_test.py": {"loc": 48, "lloc": 24, "sloc": 28, "comments": 14, "multi": 0, "blank": 6, "single_comments": 14}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/read_tf_events.py": {"loc": 69, "lloc": 39, "sloc": 43, "comments": 18, "multi": 0, "blank": 8, "single_comments": 18}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/run_classifier.py": {"loc": 1129, "lloc": 607, "sloc": 754, "comments": 102, "multi": 18, "blank": 206, "single_comments": 151}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/run_classifier_ner.py": {"loc": 1124, "lloc": 595, "sloc": 783, "comments": 112, "multi": 25, "blank": 188, "single_comments": 128}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/run_classifier_with_tfhub.py": {"loc": 314, "lloc": 156, "sloc": 220, "comments": 29, "multi": 0, "blank": 61, "single_comments": 33}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/run_pretraining.py": {"loc": 560, "lloc": 276, "sloc": 413, "comments": 47, "multi": 0, "blank": 97, "single_comments": 50}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/run_squad.py": {"loc": 1370, "lloc": 735, "sloc": 969, "comments": 139, "multi": 3, "blank": 245, "single_comments": 153}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/run_squad_trtis_client.py": {"loc": 208, "lloc": 124, "sloc": 139, "comments": 6, "multi": 7, "blank": 58, "single_comments": 4}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/tf_metrics.py": {"loc": 215, "lloc": 84, "sloc": 89, "comments": 0, "multi": 100, "blank": 24, "single_comments": 2}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/tokenization.py": {"loc": 399, "lloc": 257, "sloc": 254, "comments": 49, "multi": 16, "blank": 68, "single_comments": 61}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/tokenization_test.py": {"loc": 133, "lloc": 68, "sloc": 89, "comments": 14, "multi": 0, "blank": 30, "single_comments": 14}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/__init__.py": {"loc": 15, "lloc": 0, "sloc": 0, "comments": 14, "multi": 0, "blank": 1, "single_comments": 14}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/utils/create_glue_data.py": {"loc": 512, "lloc": 306, "sloc": 331, "comments": 45, "multi": 18, "blank": 84, "single_comments": 79}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/utils/create_pretraining_data.py": {"loc": 442, "lloc": 260, "sloc": 294, "comments": 50, "multi": 0, "blank": 91, "single_comments": 57}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/utils/create_squad_data.py": {"loc": 561, "lloc": 314, "sloc": 411, "comments": 69, "multi": 3, "blank": 72, "single_comments": 75}, "huawei-noah.Pretrained-Language-Model/NEZHA-TensorFlow/utils/utils.py": {"loc": 75, "lloc": 44, "sloc": 46, "comments": 17, "multi": 0, "blank": 13, "single_comments": 16}, "huawei-noah.Pretrained-Language-Model/PMLM/create_pretraining_data.py": {"loc": 470, "lloc": 273, "sloc": 310, "comments": 63, "multi": 0, "blank": 90, "single_comments": 70}, "huawei-noah.Pretrained-Language-Model/PMLM/modeling.py": {"loc": 1267, "lloc": 432, "sloc": 613, "comments": 134, "multi": 320, "blank": 189, "single_comments": 145}, "huawei-noah.Pretrained-Language-Model/TinyBERT/data_augmentation.py": {"loc": 318, "lloc": 205, "sloc": 220, "comments": 21, "multi": 7, "blank": 68, "single_comments": 23}, "huawei-noah.Pretrained-Language-Model/TinyBERT/general_distill.py": {"loc": 518, "lloc": 319, "sloc": 405, "comments": 33, "multi": 0, "blank": 83, "single_comments": 30}, "huawei-noah.Pretrained-Language-Model/TinyBERT/pregenerate_training_data.py": {"loc": 412, "lloc": 264, "sloc": 288, "comments": 59, "multi": 6, "blank": 60, "single_comments": 58}, "huawei-noah.Pretrained-Language-Model/TinyBERT/task_distill.py": {"loc": 1092, "lloc": 692, "sloc": 798, "comments": 31, "multi": 10, "blank": 197, "single_comments": 87}, "huawei-noah.Pretrained-Language-Model/TinyBERT/transformer/file_utils.py": {"loc": 269, "lloc": 182, "sloc": 170, "comments": 17, "multi": 32, "blank": 50, "single_comments": 17}, "huawei-noah.Pretrained-Language-Model/TinyBERT/transformer/modeling.py": {"loc": 1142, "lloc": 613, "sloc": 678, "comments": 55, "multi": 217, "blank": 187, "single_comments": 60}, "huawei-noah.Pretrained-Language-Model/TinyBERT/transformer/optimization.py": {"loc": 302, "lloc": 162, "sloc": 160, "comments": 38, "multi": 64, "blank": 42, "single_comments": 36}, "huawei-noah.Pretrained-Language-Model/TinyBERT/transformer/tokenization.py": {"loc": 389, "lloc": 236, "sloc": 247, "comments": 45, "multi": 33, "blank": 53, "single_comments": 56}, "huawei-noah.Pretrained-Language-Model/TinyBERT/transformer/__init__.py": {"loc": 12, "lloc": 5, "sloc": 8, "comments": 0, "multi": 0, "blank": 4, "single_comments": 0}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/mindspore_hub_conf.py": {"loc": 49, "lloc": 13, "sloc": 27, "comments": 14, "multi": 6, "blank": 2, "single_comments": 14}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/run_general_distill.py": {"loc": 158, "lloc": 100, "sloc": 121, "comments": 16, "multi": 3, "blank": 17, "single_comments": 17}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/run_task_distill.py": {"loc": 325, "lloc": 212, "sloc": 254, "comments": 18, "multi": 15, "blank": 37, "single_comments": 19}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/__init__.py": {"loc": 0, "lloc": 0, "sloc": 0, "comments": 0, "multi": 0, "blank": 0, "single_comments": 0}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/src/assessment_method.py": {"loc": 54, "lloc": 34, "sloc": 30, "comments": 14, "multi": 0, "blank": 6, "single_comments": 18}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/src/dataset.py": {"loc": 68, "lloc": 40, "sloc": 42, "comments": 15, "multi": 0, "blank": 8, "single_comments": 18}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/src/gd_config.py": {"loc": 74, "lloc": 9, "sloc": 51, "comments": 14, "multi": 8, "blank": 1, "single_comments": 14}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/src/td_config.py": {"loc": 98, "lloc": 13, "sloc": 72, "comments": 14, "multi": 5, "blank": 6, "single_comments": 15}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/src/tinybert_for_gd_td.py": {"loc": 600, "lloc": 406, "sloc": 465, "comments": 32, "multi": 60, "blank": 34, "single_comments": 41}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/src/tinybert_model.py": {"loc": 995, "lloc": 471, "sloc": 709, "comments": 44, "multi": 174, "blank": 55, "single_comments": 57}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/src/utils.py": {"loc": 143, "lloc": 95, "sloc": 93, "comments": 14, "multi": 19, "blank": 12, "single_comments": 19}, "huawei-noah.Pretrained-Language-Model/TinyBERT-MindSpore/src/__init__.py": {"loc": 0, "lloc": 0, "sloc": 0, "comments": 0, "multi": 0, "blank": 0, "single_comments": 0}}
