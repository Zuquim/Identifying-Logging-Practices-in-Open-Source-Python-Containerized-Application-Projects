{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular text analysis technique is called topic modeling. The ultimate goal of topic modeling is to find various topics that are present in your corpus. Each document in the corpus will be made up of at least one topic, if not multiple topics.\n",
    "\n",
    "In this notebook, we will be covering the steps on how to do **Latent Dirichlet Allocation (LDA)**, which is one of many topic modeling techniques. It was specifically designed for text data.\n",
    "\n",
    "To use a topic modeling technique, you need to provide (1) a document-term matrix and (2) the number of topics you would like the algorithm to pick up.\n",
    "\n",
    "Once the topic modeling technique is applied, your job as a human is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, you can try changing up the number of topics, the terms in the document-term matrix, model parameters, or even try a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #1 (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaccount</th>\n",
       "      <th>aaccountid</th>\n",
       "      <th>aaccountusername</th>\n",
       "      <th>aad</th>\n",
       "      <th>aadclientappid</th>\n",
       "      <th>aadclientid</th>\n",
       "      <th>...</th>\n",
       "      <th>非交易日</th>\n",
       "      <th>非交易日formatdaystrftimeymd</th>\n",
       "      <th>非插件</th>\n",
       "      <th>非法url</th>\n",
       "      <th>非盘中</th>\n",
       "      <th>非高价值需求</th>\n",
       "      <th>页码</th>\n",
       "      <th>预计至少有d条路线</th>\n",
       "      <th>验证用户密码时报错</th>\n",
       "      <th>默认采用等权重方式</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRITICAL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBUG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERROR</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFO</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARNING</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          aa  aaaa  aaaaa  aac  aaccount  aaccountid  aaccountusername  aad  \\\n",
       "CRITICAL   0     0      0    0         0           0                 0    0   \n",
       "DEBUG      1     0      0    0         0           0                 0    0   \n",
       "ERROR      0     0      0    0         1           0                 0    0   \n",
       "INFO       4     1      0    0         1           0                 2    9   \n",
       "WARNING    2     0      3    1         0           1                 0    0   \n",
       "\n",
       "          aadclientappid  aadclientid  ...  非交易日  非交易日formatdaystrftimeymd  \\\n",
       "CRITICAL               0            0  ...     0                         0   \n",
       "DEBUG                  0            0  ...     0                         0   \n",
       "ERROR                  0            0  ...     0                         0   \n",
       "INFO                   2            0  ...     0                         0   \n",
       "WARNING                0            1  ...    18                         1   \n",
       "\n",
       "          非插件  非法url  非盘中  非高价值需求  页码  预计至少有d条路线  验证用户密码时报错  默认采用等权重方式  \n",
       "CRITICAL    0      0    0       0   0          0          0          0  \n",
       "DEBUG       1      0    0       0   0          0          0          0  \n",
       "ERROR       0      0    0       0   2          0          1          0  \n",
       "INFO        0      1    1       0   0          2          0          0  \n",
       "WARNING     0      0    0       1   0          0          0          1  \n",
       "\n",
       "[5 rows x 103484 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRITICAL</th>\n",
       "      <th>DEBUG</th>\n",
       "      <th>ERROR</th>\n",
       "      <th>INFO</th>\n",
       "      <th>WARNING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aac</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaccount</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CRITICAL  DEBUG  ERROR  INFO  WARNING\n",
       "aa               0      1      0     4        2\n",
       "aaaa             0      0      0     1        0\n",
       "aaaaa            0      0      0     0        3\n",
       "aac              0      0      0     0        1\n",
       "aaccount         0      0      1     1        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term), we need to specify two other parameters - the number of topics and the number of passes. Let's start the number of topics at 2, see if the results make sense, and increase the number from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"deprecated\" + 0.004*\"deprecationwarning\" + 0.003*\"module\" + 0.003*\"config\" + 0.003*\"volume\" + 0.003*\"instead\" + 0.003*\"update\" + 0.003*\"connection\" + 0.003*\"command\" + 0.002*\"result\"'),\n",
       " (1,\n",
       "  '0.004*\"starting\" + 0.004*\"loading\" + 0.004*\"training\" + 0.003*\"successfully\" + 0.003*\"epoch\" + 0.003*\"created\" + 0.003*\"test\" + 0.003*\"task\" + 0.002*\"size\" + 0.002*\"results\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=20)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"deprecated\" + 0.006*\"deprecationwarning\" + 0.004*\"instead\" + 0.004*\"module\" + 0.003*\"unknown\" + 0.003*\"config\" + 0.003*\"update\" + 0.003*\"missing\" + 0.003*\"configuration\" + 0.003*\"api\"'),\n",
       " (1,\n",
       "  '0.004*\"starting\" + 0.004*\"loading\" + 0.004*\"training\" + 0.003*\"successfully\" + 0.003*\"epoch\" + 0.003*\"created\" + 0.003*\"test\" + 0.003*\"task\" + 0.003*\"size\" + 0.003*\"results\"'),\n",
       " (2,\n",
       "  '0.004*\"result\" + 0.004*\"volume\" + 0.003*\"host\" + 0.003*\"state\" + 0.003*\"connection\" + 0.003*\"command\" + 0.003*\"checking\" + 0.003*\"event\" + 0.003*\"status\" + 0.002*\"search\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=30)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"deprecated\" + 0.000*\"deprecationwarning\" + 0.000*\"volume\" + 0.000*\"connection\" + 0.000*\"update\" + 0.000*\"config\" + 0.000*\"job\" + 0.000*\"group\" + 0.000*\"instead\" + 0.000*\"state\"'),\n",
       " (1,\n",
       "  '0.004*\"result\" + 0.004*\"volume\" + 0.003*\"host\" + 0.003*\"state\" + 0.003*\"command\" + 0.003*\"connection\" + 0.003*\"checking\" + 0.003*\"event\" + 0.003*\"status\" + 0.003*\"search\"'),\n",
       " (2,\n",
       "  '0.004*\"unknown\" + 0.004*\"unexpected\" + 0.004*\"api\" + 0.003*\"config\" + 0.003*\"occurred\" + 0.003*\"update\" + 0.003*\"missing\" + 0.003*\"connect\" + 0.003*\"configuration\" + 0.003*\"connection\"'),\n",
       " (3,\n",
       "  '0.007*\"deprecated\" + 0.005*\"deprecationwarning\" + 0.003*\"instead\" + 0.003*\"training\" + 0.003*\"starting\" + 0.003*\"loading\" + 0.003*\"module\" + 0.003*\"config\" + 0.002*\"task\" + 0.002*\"size\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=40)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"starting\" + 0.004*\"loading\" + 0.004*\"training\" + 0.003*\"successfully\" + 0.003*\"epoch\" + 0.003*\"created\" + 0.003*\"test\" + 0.003*\"task\" + 0.003*\"size\" + 0.003*\"results\"'),\n",
       " (1,\n",
       "  '0.000*\"deprecated\" + 0.000*\"module\" + 0.000*\"deprecationwarning\" + 0.000*\"update\" + 0.000*\"command\" + 0.000*\"connection\" + 0.000*\"received\" + 0.000*\"config\" + 0.000*\"group\" + 0.000*\"volume\"'),\n",
       " (2,\n",
       "  '0.008*\"deprecated\" + 0.005*\"deprecationwarning\" + 0.004*\"instead\" + 0.003*\"module\" + 0.003*\"result\" + 0.003*\"volume\" + 0.003*\"state\" + 0.003*\"host\" + 0.003*\"config\" + 0.003*\"connection\"'),\n",
       " (3,\n",
       "  '0.004*\"unknown\" + 0.004*\"unexpected\" + 0.004*\"api\" + 0.003*\"config\" + 0.003*\"occurred\" + 0.003*\"update\" + 0.003*\"configuration\" + 0.003*\"missing\" + 0.003*\"connect\" + 0.003*\"command\"'),\n",
       " (4,\n",
       "  '0.000*\"deprecated\" + 0.000*\"deprecationwarning\" + 0.000*\"instead\" + 0.000*\"config\" + 0.000*\"module\" + 0.000*\"volume\" + 0.000*\"removed\" + 0.000*\"result\" + 0.000*\"host\" + 0.000*\"update\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 5\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=50)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These topics aren't looking too great. We've tried modifying our parameters. Let's try modifying our terms list as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #2 (Nouns Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One popular trick is to look only at terms that are from one part of speech (only nouns, only adjectives, etc.). Check out the UPenn tag set: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import download, word_tokenize, pos_tag\n",
    "\n",
    "download('punkt')\n",
    "download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRITICAL</th>\n",
       "      <td>failed getting list of jobs error no place to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBUG</th>\n",
       "      <td>jsondumps  response  url errorurl code errorco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERROR</th>\n",
       "      <td>start failed stop failed shutdown watchad fail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFO</th>\n",
       "      <td>loading detect modules based on eventlog start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARNING</th>\n",
       "      <td>index  not foundformatnameindexname replacing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    content\n",
       "CRITICAL  failed getting list of jobs error no place to ...\n",
       "DEBUG     jsondumps  response  url errorurl code errorco...\n",
       "ERROR     start failed stop failed shutdown watchad fail...\n",
       "INFO      loading detect modules based on eventlog start...\n",
       "WARNING   index  not foundformatnameindexname replacing ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRITICAL</th>\n",
       "      <td>list jobs place jobs layers lenselflayers lens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBUG</th>\n",
       "      <td>jsondumps response errorurl code errorcode msg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERROR</th>\n",
       "      <td>start stop watchad action action domain params...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFO</th>\n",
       "      <td>detect modules start consumer register callbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARNING</th>\n",
       "      <td>index argument replacement user password authe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    content\n",
       "CRITICAL  list jobs place jobs layers lenselflayers lens...\n",
       "DEBUG     jsondumps response errorurl code errorcode msg...\n",
       "ERROR     start stop watchad action action domain params...\n",
       "INFO      detect modules start consumer register callbac...\n",
       "WARNING   index argument replacement user password authe..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the contents to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.content.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbreviations</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>abort</th>\n",
       "      <th>aborting</th>\n",
       "      <th>abortion</th>\n",
       "      <th>aboutinformationpropertyname</th>\n",
       "      <th>abovestd</th>\n",
       "      <th>abs</th>\n",
       "      <th>...</th>\n",
       "      <th>错误信息</th>\n",
       "      <th>错误信息inccheckresulterror</th>\n",
       "      <th>错误信息tracebackformatexc</th>\n",
       "      <th>非交易日</th>\n",
       "      <th>非交易日formatdaystrftimeymd</th>\n",
       "      <th>非法url</th>\n",
       "      <th>非盘中</th>\n",
       "      <th>页码</th>\n",
       "      <th>预计至少有d条路线</th>\n",
       "      <th>验证用户密码时报错</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRITICAL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBUG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERROR</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFO</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARNING</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          abandon  abbreviations  abilities  ability  abort  aborting  \\\n",
       "CRITICAL        0              0          0        0      1         0   \n",
       "DEBUG           0              0          2        5     14         3   \n",
       "ERROR           0              0          0        2     13         0   \n",
       "INFO            0              1          0        4      3         1   \n",
       "WARNING         6              0          0        8      6         2   \n",
       "\n",
       "          abortion  aboutinformationpropertyname  abovestd  abs  ...  错误信息  \\\n",
       "CRITICAL         0                             0         0    0  ...     0   \n",
       "DEBUG            0                             0         0    1  ...     3   \n",
       "ERROR            0                             0         1    0  ...     7   \n",
       "INFO             4                             0         0    0  ...     0   \n",
       "WARNING          1                             1         0    0  ...     8   \n",
       "\n",
       "          错误信息inccheckresulterror  错误信息tracebackformatexc  非交易日  \\\n",
       "CRITICAL                        0                       0     0   \n",
       "DEBUG                           1                       1     0   \n",
       "ERROR                           0                       0     0   \n",
       "INFO                            0                       0     0   \n",
       "WARNING                         0                      12    18   \n",
       "\n",
       "          非交易日formatdaystrftimeymd  非法url  非盘中  页码  预计至少有d条路线  验证用户密码时报错  \n",
       "CRITICAL                         0      0    0   0          0          0  \n",
       "DEBUG                            0      0    0   0          0          0  \n",
       "ERROR                            0      0    0   2          0          1  \n",
       "INFO                             0      1    1   0          2          0  \n",
       "WARNING                          1      0    0   0          0          0  \n",
       "\n",
       "[5 rows x 72268 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = [\n",
    "    'like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "    'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said',\n",
    "    'aa', 'aaaa', 'aaaaa', 'aaccount', 'aaccountusername', 'aad', 'aadclientid',\n",
    "    'aadendpoint', 'aadtokenbaseerrormessage', 'aadtenantid', 'aadtype',\n",
    "    'aaicon', 'aautoscalinggroupname', 'aaves', 'ab', 'abandonedtaskidentifier',\n",
    "    'abbreviateclientinfo', 'abc', 'abck', 'abci', 'abcdeformatoptstr', \n",
    "    'abepisodenumbers', 'abi', 'abid', 'abilityid', 'abode', 'abortconnection',\n",
    "    'aborterror', 'abortingformat', 'abortmessage', 'abortwithpayloadreasonnamespace',\n",
    "    'd', 'data', 'e', 'err', 'ex', 'exc', 'excinfotrue', 'exx', 'f',\n",
    "    'ferror', 'format', 'formate', 'id', 'msg', 'n', 'r', 'self', \n",
    "    'selfname', 'str', 'stre', 'type', 'x'\n",
    "]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.content)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.030*\"error\" + 0.011*\"file\" + 0.011*\"exception\" + 0.006*\"request\" + 0.006*\"path\" + 0.006*\"response\" + 0.005*\"message\" + 0.005*\"volume\" + 0.005*\"value\" + 0.004*\"connection\"'),\n",
       " (1,\n",
       "  '0.012*\"file\" + 0.009*\"error\" + 0.008*\"use\" + 0.007*\"version\" + 0.007*\"model\" + 0.005*\"value\" + 0.004*\"path\" + 0.004*\"module\" + 0.004*\"request\" + 0.004*\"user\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"error\" + 0.001*\"file\" + 0.000*\"version\" + 0.000*\"request\" + 0.000*\"model\" + 0.000*\"use\" + 0.000*\"exception\" + 0.000*\"path\" + 0.000*\"value\" + 0.000*\"user\"'),\n",
       " (1,\n",
       "  '0.012*\"error\" + 0.010*\"file\" + 0.008*\"use\" + 0.007*\"value\" + 0.007*\"version\" + 0.006*\"path\" + 0.005*\"request\" + 0.005*\"module\" + 0.005*\"response\" + 0.005*\"message\"'),\n",
       " (2,\n",
       "  '0.028*\"error\" + 0.013*\"file\" + 0.010*\"exception\" + 0.006*\"model\" + 0.005*\"request\" + 0.005*\"path\" + 0.005*\"version\" + 0.005*\"message\" + 0.004*\"config\" + 0.004*\"user\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"file\" + 0.006*\"error\" + 0.005*\"path\" + 0.005*\"model\" + 0.005*\"request\" + 0.005*\"version\" + 0.005*\"volume\" + 0.005*\"response\" + 0.004*\"result\" + 0.004*\"state\"'),\n",
       " (1,\n",
       "  '0.018*\"use\" + 0.015*\"error\" + 0.011*\"file\" + 0.010*\"version\" + 0.009*\"value\" + 0.008*\"module\" + 0.005*\"exception\" + 0.005*\"model\" + 0.004*\"path\" + 0.004*\"method\"'),\n",
       " (2,\n",
       "  '0.060*\"error\" + 0.021*\"exception\" + 0.014*\"file\" + 0.007*\"request\" + 0.007*\"path\" + 0.006*\"message\" + 0.005*\"response\" + 0.005*\"value\" + 0.004*\"server\" + 0.004*\"configuration\"'),\n",
       " (3,\n",
       "  '0.000*\"file\" + 0.000*\"error\" + 0.000*\"use\" + 0.000*\"version\" + 0.000*\"path\" + 0.000*\"request\" + 0.000*\"value\" + 0.000*\"config\" + 0.000*\"state\" + 0.000*\"model\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"file\" + 0.009*\"model\" + 0.006*\"version\" + 0.004*\"size\" + 0.004*\"results\" + 0.004*\"test\" + 0.004*\"task\" + 0.004*\"path\" + 0.004*\"job\" + 0.004*\"user\"'),\n",
       " (1,\n",
       "  '0.000*\"error\" + 0.000*\"file\" + 0.000*\"value\" + 0.000*\"exception\" + 0.000*\"path\" + 0.000*\"request\" + 0.000*\"version\" + 0.000*\"volume\" + 0.000*\"task\" + 0.000*\"state\"'),\n",
       " (2,\n",
       "  '0.000*\"file\" + 0.000*\"error\" + 0.000*\"path\" + 0.000*\"version\" + 0.000*\"result\" + 0.000*\"message\" + 0.000*\"response\" + 0.000*\"request\" + 0.000*\"use\" + 0.000*\"model\"'),\n",
       " (3,\n",
       "  '0.032*\"error\" + 0.012*\"file\" + 0.012*\"exception\" + 0.007*\"request\" + 0.007*\"path\" + 0.006*\"response\" + 0.006*\"message\" + 0.006*\"volume\" + 0.005*\"value\" + 0.005*\"connection\"'),\n",
       " (4,\n",
       "  '0.018*\"use\" + 0.016*\"error\" + 0.011*\"file\" + 0.010*\"version\" + 0.009*\"value\" + 0.008*\"module\" + 0.005*\"exception\" + 0.005*\"model\" + 0.004*\"path\" + 0.004*\"method\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 5 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=5, id2word=id2wordn, passes=25)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRITICAL</th>\n",
       "      <td>list jobs place jobs layers lenselfjobs lensel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBUG</th>\n",
       "      <td>jsondumps response url errorurl code errorcode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERROR</th>\n",
       "      <td>start stop shutdown watchad action install act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFO</th>\n",
       "      <td>detect modules eventlog start consumer registe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARNING</th>\n",
       "      <td>index foundformatnameindexname argument argume...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    content\n",
       "CRITICAL  list jobs place jobs layers lenselfjobs lensel...\n",
       "DEBUG     jsondumps response url errorurl code errorcode...\n",
       "ERROR     start stop shutdown watchad action install act...\n",
       "INFO      detect modules eventlog start consumer registe...\n",
       "WARNING   index foundformatnameindexname argument argume..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the contents to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.content.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaccountid</th>\n",
       "      <th>aadsecret</th>\n",
       "      <th>aadspobjectid</th>\n",
       "      <th>aadspobjectiddef</th>\n",
       "      <th>aanyrecipe</th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aautorev</th>\n",
       "      <th>aave</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>...</th>\n",
       "      <th>错误信息tracebackformatexc</th>\n",
       "      <th>非交易日</th>\n",
       "      <th>非交易日formatdaystrftimeymd</th>\n",
       "      <th>非插件</th>\n",
       "      <th>非法url</th>\n",
       "      <th>非盘中</th>\n",
       "      <th>页码</th>\n",
       "      <th>预计至少有d条路线</th>\n",
       "      <th>验证用户密码时报错</th>\n",
       "      <th>默认采用等权重方式</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRITICAL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBUG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERROR</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFO</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARNING</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88839 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          aaccountid  aadsecret  aadspobjectid  aadspobjectiddef  aanyrecipe  \\\n",
       "CRITICAL           0          0              0                 0           0   \n",
       "DEBUG              0          0              0                 0           0   \n",
       "ERROR              0          0              0                 0           0   \n",
       "INFO               0          0              0                 0           0   \n",
       "WARNING            1          1              1                 1           1   \n",
       "\n",
       "          aardvark  aautorev  aave  abandon  abbreviated  ...  \\\n",
       "CRITICAL         0         0     0        0            0  ...   \n",
       "DEBUG            0         0     1        0            0  ...   \n",
       "ERROR            2         1     5        0            0  ...   \n",
       "INFO             0         0     0        0            2  ...   \n",
       "WARNING          0         0     1        7            0  ...   \n",
       "\n",
       "          错误信息tracebackformatexc  非交易日  非交易日formatdaystrftimeymd  非插件  非法url  \\\n",
       "CRITICAL                       0     0                         0    0      0   \n",
       "DEBUG                          1     0                         0    1      0   \n",
       "ERROR                          0     0                         0    0      0   \n",
       "INFO                           0     0                         0    0      1   \n",
       "WARNING                       13    18                         1    0      0   \n",
       "\n",
       "          非盘中  页码  预计至少有d条路线  验证用户密码时报错  默认采用等权重方式  \n",
       "CRITICAL    0   0          0          0          0  \n",
       "DEBUG       0   0          0          0          0  \n",
       "ERROR       0   2          0          1          0  \n",
       "INFO        1   0          2          0          0  \n",
       "WARNING     0   0          0          0          1  \n",
       "\n",
       "[5 rows x 88839 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.content)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"element\" + 0.002*\"release\" + 0.002*\"query\" + 0.002*\"tautulli\" + 0.002*\"app\" + 0.001*\"typeother\" + 0.001*\"parserelement\" + 0.001*\"policy\" + 0.001*\"topic\" + 0.001*\"xsd\"'),\n",
       " (1,\n",
       "  '0.003*\"query\" + 0.002*\"policy\" + 0.002*\"evaluation\" + 0.002*\"volumeid\" + 0.002*\"record\" + 0.001*\"tautulli\" + 0.001*\"volumename\" + 0.001*\"success\" + 0.001*\"seeders\" + 0.001*\"text\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"query\" + 0.002*\"seeders\" + 0.002*\"policy\" + 0.002*\"volumeid\" + 0.002*\"record\" + 0.002*\"volumename\" + 0.002*\"tautulli\" + 0.002*\"title\" + 0.002*\"body\" + 0.001*\"text\"'),\n",
       " (1,\n",
       "  '0.003*\"evaluation\" + 0.002*\"num\" + 0.002*\"features\" + 0.002*\"success\" + 0.002*\"weights\" + 0.002*\"train\" + 0.002*\"eval\" + 0.002*\"accuracy\" + 0.002*\"userid\" + 0.002*\"nameselfname\"'),\n",
       " (2,\n",
       "  '0.002*\"element\" + 0.002*\"release\" + 0.002*\"query\" + 0.002*\"tautulli\" + 0.002*\"app\" + 0.002*\"typeother\" + 0.002*\"parserelement\" + 0.002*\"policy\" + 0.001*\"topic\" + 0.001*\"xsd\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"element\" + 0.002*\"release\" + 0.002*\"query\" + 0.002*\"tautulli\" + 0.002*\"app\" + 0.002*\"typeother\" + 0.002*\"parserelement\" + 0.002*\"policy\" + 0.002*\"topic\" + 0.001*\"xsd\"'),\n",
       " (1,\n",
       "  '0.003*\"query\" + 0.002*\"policy\" + 0.002*\"selfrequest\" + 0.002*\"tautulli\" + 0.002*\"record\" + 0.002*\"tensorflow\" + 0.002*\"callback\" + 0.001*\"volumeid\" + 0.001*\"body\" + 0.001*\"auth\"'),\n",
       " (2,\n",
       "  '0.003*\"query\" + 0.003*\"seeders\" + 0.002*\"volumeid\" + 0.002*\"volumename\" + 0.002*\"title\" + 0.002*\"leechers\" + 0.002*\"record\" + 0.002*\"policy\" + 0.002*\"season\" + 0.002*\"sample\"'),\n",
       " (3,\n",
       "  '0.003*\"evaluation\" + 0.002*\"num\" + 0.002*\"features\" + 0.002*\"success\" + 0.002*\"weights\" + 0.002*\"train\" + 0.002*\"eval\" + 0.002*\"accuracy\" + 0.002*\"userid\" + 0.002*\"query\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"query\" + 0.000*\"policy\" + 0.000*\"tautulli\" + 0.000*\"app\" + 0.000*\"evaluation\" + 0.000*\"userid\" + 0.000*\"topic\" + 0.000*\"weights\" + 0.000*\"gpu\" + 0.000*\"record\"'),\n",
       " (1,\n",
       "  '0.003*\"evaluation\" + 0.002*\"query\" + 0.002*\"weights\" + 0.002*\"features\" + 0.002*\"num\" + 0.002*\"app\" + 0.002*\"policy\" + 0.002*\"userid\" + 0.002*\"success\" + 0.002*\"tautulli\"'),\n",
       " (2,\n",
       "  '0.001*\"ios\" + 0.001*\"selfparent\" + 0.001*\"ffail\" + 0.001*\"criterion\" + 0.001*\"formatcriterion\" + 0.001*\"ereturncode\" + 0.001*\"levelloggingcritical\" + 0.001*\"transienttrue\" + 0.001*\"formatresultmessage\" + 0.001*\"pycryptodomex\"'),\n",
       " (3,\n",
       "  '0.004*\"query\" + 0.003*\"seeders\" + 0.002*\"volumeid\" + 0.002*\"volumename\" + 0.002*\"title\" + 0.002*\"leechers\" + 0.002*\"record\" + 0.002*\"policy\" + 0.002*\"season\" + 0.002*\"sample\"'),\n",
       " (4,\n",
       "  '0.004*\"query\" + 0.003*\"policy\" + 0.003*\"selfrequest\" + 0.003*\"tautulli\" + 0.002*\"record\" + 0.002*\"tensorflow\" + 0.002*\"callback\" + 0.002*\"volumeid\" + 0.002*\"body\" + 0.002*\"auth\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 5 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=5, id2word=id2wordna, passes=25)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Topics in Each Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 9 topic models we looked at, the nouns and adjectives, 4 topic one made the most sense. So let's pull that down here and run it through some more iterations to get more fine-tuned topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"element\" + 0.002*\"release\" + 0.002*\"query\" + 0.002*\"tautulli\" + 0.002*\"app\" + 0.002*\"typeother\" + 0.002*\"parserelement\" + 0.002*\"policy\" + 0.002*\"topic\" + 0.001*\"xsd\"'),\n",
       " (1,\n",
       "  '0.003*\"query\" + 0.003*\"seeders\" + 0.002*\"volumeid\" + 0.002*\"volumename\" + 0.002*\"title\" + 0.002*\"leechers\" + 0.002*\"record\" + 0.002*\"season\" + 0.002*\"policy\" + 0.002*\"sample\"'),\n",
       " (2,\n",
       "  '0.003*\"evaluation\" + 0.002*\"num\" + 0.002*\"features\" + 0.002*\"success\" + 0.002*\"weights\" + 0.002*\"train\" + 0.002*\"eval\" + 0.002*\"accuracy\" + 0.002*\"userid\" + 0.002*\"nameselfname\"'),\n",
       " (3,\n",
       "  '0.003*\"query\" + 0.002*\"policy\" + 0.002*\"selfrequest\" + 0.002*\"tautulli\" + 0.002*\"record\" + 0.002*\"tensorflow\" + 0.002*\"callback\" + 0.001*\"volumeid\" + 0.001*\"body\" + 0.001*\"auth\"')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"element\" + 0.002*\"release\" + 0.002*\"query\" + 0.002*\"tautulli\" + 0.002*\"app\" + 0.002*\"typeother\" + 0.002*\"parserelement\" + 0.002*\"policy\" + 0.002*\"topic\" + 0.002*\"xsd\"'),\n",
       " (1,\n",
       "  '0.003*\"query\" + 0.003*\"policy\" + 0.003*\"selfrequest\" + 0.002*\"tautulli\" + 0.002*\"record\" + 0.002*\"tensorflow\" + 0.002*\"callback\" + 0.002*\"volumeid\" + 0.002*\"body\" + 0.001*\"auth\"'),\n",
       " (2,\n",
       "  '0.003*\"query\" + 0.002*\"evaluation\" + 0.002*\"seeders\" + 0.002*\"policy\" + 0.002*\"success\" + 0.002*\"volumeid\" + 0.002*\"num\" + 0.002*\"timetime\" + 0.002*\"volumename\" + 0.001*\"record\"'),\n",
       " (3,\n",
       "  '0.000*\"matchgroups\" + 0.000*\"matchindex\" + 0.000*\"connectionuri\" + 0.000*\"joiner\" + 0.000*\"formatselfaction\" + 0.000*\"bars\" + 0.000*\"selfsecondary\" + 0.000*\"selfgetsizeinazurerelpath\" + 0.000*\"ftried\" + 0.000*\"tasknames\"'),\n",
       " (4,\n",
       "  '0.000*\"toolkit\" + 0.000*\"joiner\" + 0.000*\"joininvalid\" + 0.000*\"clip\" + 0.000*\"outofprocess\" + 0.000*\"joinlayerseries\" + 0.000*\"outputcsverror\" + 0.000*\"cloudnodecomputeid\" + 0.000*\"outputunicodeencodeerror\" + 0.000*\"otherworkersbuiltinhash\"')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=5, id2word=id2wordna, passes=160)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These four topics look pretty decent. Let's settle on these for now.\n",
    "* Topic 0: mom, parents\n",
    "* Topic 1: husband, wife\n",
    "* Topic 2: guns\n",
    "* Topic 3: profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'CRITICAL'), (2, 'DEBUG'), (1, 'ERROR'), (2, 'INFO'), (0, 'WARNING')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each content contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For a first pass of LDA, these kind of make sense to me, so we'll call it a day for now.\n",
    "* Topic 0: mom, parents [Anthony, Hasan, Louis, Ricky]\n",
    "* Topic 1: husband, wife [Ali, John, Mike]\n",
    "* Topic 2: guns [Bill, Bo, Jim]\n",
    "* Topic 3: profanity [Dave, Joe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Try further modifying the parameters of the topic models above and see if you can get better topics.\n",
    "2. Create a new topic model that includes terms from a different [part of speech](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) and see if you can get better topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
